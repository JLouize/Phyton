{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representações Distribuídas de Texto e Modelagem de Tópicos\n",
    "\n",
    "<b> DOCENTES: </b>\n",
    "<pre>\n",
    "     Prof. Renato Rocha de Souza\n",
    "     Prof. Mauricio Barcellos Almeida\n",
    "     Profa. Renata Maria Abrantes Baracho Porto\n",
    "</pre>\n",
    "\n",
    "<b> DISCENTE: </b> Jeanne Louize Emygdio </br>\n",
    "\n",
    "<b> OBJETIVO: </b> Identificar artigos científicos disponíveis na base Medline voltados à temática de uso do padrão OpenEHR - Uma ontologia para modelagem de dados médicos e que possam compor meu acervo particular de referencial teórico para a escrita da tese. \n",
    "\n",
    "<b> Estratégia selecionada: </b>  Modelagem de tópicos e clusterização de documentos. \n",
    "\n",
    "<b> Etapas: </b>\n",
    "<pre>\n",
    "    1.\tFinalização do curso de Python disponibilizado pelo Prof. Renato\n",
    "    2.\tInstalação e configuração da plataforma de desenvolvimento\n",
    "    3.\tFork da área de MMD do Prof. Renato no Github\n",
    "    4.\tEstudo do notebook 4.2_TopicModeling_Clustering_Documents.ipynb\n",
    "    5.\tImportação das bibliotecas necessárias\n",
    "    6.\tDesenvolvimento do novo notebook de acordo com as passagens previstas no 4.2.\n",
    "</pre>\n",
    "\n",
    "<b>Resultados esperados: </b>\n",
    "<pre>\n",
    "\t- Desenvolvimento de habilidades de programação na linguagem Python;\n",
    "\t- Melhor compreensão das estratégias de obtenção de documentos, análises textuais e clusterização;\n",
    "\t- Montagem de biblioteca de artigos relevantes na temática selecionada de forma ágil.\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Louize\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louize\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# urllib - Módulo que reúne funções de alto nível para acesso à internet. \n",
    "# Documentation: https://docs.python.org/3/library/urllib.html | \n",
    "#                https://docs.python.org/3/library/urllib.request.html#module-urllib.request\n",
    "import urllib as url                 \n",
    "\n",
    "# BeautifulSoup - Biblioteca utilizada para extrair dados de arquivos HTML e XML.\n",
    "# Documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# NLTK - Biblioteca para trabalhar com processamentos de linguagem natural\n",
    "# Documentation: https://pypi.python.org/pypi/nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus       import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize     import word_tokenize\n",
    "\n",
    "# Biblioteca para auxílio à contagem de freqência de ocorrência de palavras em um texto\n",
    "from collections import Counter\n",
    "\n",
    "# Bilioteca para lidar com processamento de strings através de expressões regulares\n",
    "import re \n",
    "\n",
    "# Biblioteca que disponibiliza recursos para modelagem de tópicos\n",
    "import gensim\n",
    "\n",
    "#from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louize\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Louize\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Acessando a página do Portal da Capes. O objetivo é pesquisar a base PUBMED.\n",
    "# Realizei acesso com e sem autenticação e o resultado da pesquisa foi o mesmo. A codificação segue sem autenticação.\n",
    "# O link alvo é: https://www.ncbi.nlm.nih.gov/pubmed/\n",
    "# Termo pesquisado: OpenEHR. Encontrei 148 artigos.\n",
    "# Outros termos para pesquisa futura: (((ontology[Title]) OR ontology[Abstract]) AND (owl OR 'web ontology' OR 'web ontologies') \n",
    "\n",
    "# Lógica utilizada descrita por linhas: Recuperar conteúdo da página usando urllib, e visualizar resultados tratados \n",
    "#                                       pela biblioteca BeautifulSoup.\n",
    "# L20: Estrutura de controle para tratar adequadamente possíveis erros na execução dos comandos (try...except)\n",
    "# L21: Variável v_terbus recebe a string que vou usar para buscar o termo OpenEHR no título e abstract\n",
    "# L22: Acesso à url completa da página acrescida do conteúdo da variável v_terbus, utilizando a função urlib\n",
    "# L23: Execução da biblioteca BeautifulSoup sobre a Url acessada para estudar os elementos da página e extrair os \n",
    "#      desejados. O resultado é armazenado na variável v_soup. O comando print(v_soup.prettify()) permite ver toda \n",
    "#      a estrutura da página armazenado na variável.\n",
    "# L24: Declaração do vetor v_titles para armazenamento dos títulos encontrados\n",
    "# L27 a 29: Após conhecimento dos elementos, busquei as classes que tivessem o valor title e que estivessem dentro de uma \n",
    "#      tag <p> (parágrafo) e, em seus resultados, busquei os conteúdos das tags <a>, que me levariam aos títulos dos \n",
    "#      artigos. Estruturei dois loops para analisar os dois resultados aninhados. E em seguida armazenei cada título no \n",
    "#      vetor v_titles.\n",
    "\n",
    "try:   \n",
    "   v_terbus = '(OpenEHR[Title]+OR+OpenEHR[Abstract])' \n",
    "   v_url    = url.request.urlopen('https://www.ncbi.nlm.nih.gov/pubmed/?term='+v_terbus) \n",
    "   v_soup   = bs(v_url,'html.parser')\n",
    "   v_titles = [] # Declaração de um vetor para armazenar os títulos encontrados\n",
    "                                                    \n",
    "   for v_elemento in v_soup.find_all('p', class_='title'):                 \n",
    "      for n in bs(v_elemento.find('a').text): # Tentando extrair apenas a parte textual de cada trecho html\n",
    "          v_titles.append(n)        \n",
    "except url.error:\n",
    "   print('Falha na conexão!')\n",
    "   exit(1) #interrompe  a execução do programa              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 20\n"
     ]
    }
   ],
   "source": [
    "# Conferindo quantos títulos de artigos foram armazenados no vetor v_title\n",
    "# Problema encontrado: não consegui ainda fazer o sistema localizar os 148 artigos, ele só está considerando os que \n",
    "# foram exibidos na primeira página da busca (20 artigos).\n",
    "print(\"Number of documents:\",len(v_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Topic Interoperability and EHR: Combining openEHR, SNOMED, IHE, and Continua as approaches to interoperability on national eHealth.\n",
      "Bridging the Gap Between the Social and the Technical: The Enrolment of Socio-Technical Information Architects to Cope with the Two-Level Model of EPR Systems.\n",
      "Domain Modeling and Application Development of an Archetype- and XML-based EHRS. Practical Experiences and Lessons Learnt.\n",
      "Applying an Archetype-Based Approach to Electroencephalography/Event-Related Potential Experiments in the EEGBase Resource.\n",
      "Querying Archetype-Based Electronic Health Records Using Hadoop and Dewey Encoding of openEHR Models.\n",
      "Introducing a Method for Transformation of Paper-Based Research Data into Concept-Based Representation with openEHR.\n",
      "Integration of Hospital Information and Clinical Decision Support Systems to Enable the Reuse of Electronic Health Record Data.\n",
      "Structuring Legacy Pathology Reports by openEHR Archetypes to Enable Semantic Querying.\n",
      "A Survey of Standard Information Models for Clinical Decision Support Systems.\n",
      "Applying openEHR's Guideline Definition Language to the SITS international stroke treatment registry: a European retrospective observational study.\n",
      "A Scalable Data Access Layer to Manage Structured Heterogeneous Biomedical Data.\n",
      "Open data models for smart health interconnected applications: the example of openEHR.\n",
      "Integrating semantic dimension into openEHR archetypes for the management of cerebral palsy electronic medical records.\n",
      "Automated population of an i2b2 clinical data warehouse from an openEHR-based data repository.\n",
      "Building Chronic Kidney Disease Clinical Practice Guidelines Using the openEHR Guideline Definition Language.\n",
      "Modelling of Operative Report Documents for Data Integration into an openEHR-Based Enterprise Data Warehouse.\n",
      "A methodology based on openEHR archetypes and software agents for developing e-health applications reusing legacy systems.\n",
      "An Implementation of Clinical Data Repository with openEHR Approach: From Data Modeling to Architecture.\n",
      "An update on OpenEHR archetypes in Norway: Response to article Christensen B & Ellingsen G: \"Evaluating Model-Driven Development for large-scale EHRs through the openEHR approach\" IJMI May 2016, Volume 89, pages 43-54.\n",
      "Analysis of the process of representing clinical statements for decision-support applications: a comparison of openEHR archetypes and HL7 virtual medical record.\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os artigos armazenados\n",
    "# Comentário: Não consegui ainda remover as tags com BeautifulSoup, então utilizei a biblioteca 're' e funcionou!\n",
    "#             Este código deverá ser otimizado no futuro\n",
    "v_count = 0\n",
    "while v_count <= 19:\n",
    "   v_titles[v_count] = (re.sub('<[^>]+?>', '', v_titles[v_count]))\n",
    "   print(v_titles[v_count])\n",
    "   v_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['special', 'topic', 'interoperability', 'and', 'ehr', ':', 'combining', 'openehr', ',', 'snomed', ',', 'ihe', ',', 'and', 'continua', 'as', 'approaches', 'to', 'interoperability', 'on', 'national', 'ehealth', '.'], ['bridging', 'the', 'gap', 'between', 'the', 'social', 'and', 'the', 'technical', ':', 'the', 'enrolment', 'of', 'socio-technical', 'information', 'architects', 'to', 'cope', 'with', 'the', 'two-level', 'model', 'of', 'epr', 'systems', '.'], ['domain', 'modeling', 'and', 'application', 'development', 'of', 'an', 'archetype-', 'and', 'xml-based', 'ehrs', '.', 'practical', 'experiences', 'and', 'lessons', 'learnt', '.'], ['applying', 'an', 'archetype-based', 'approach', 'to', 'electroencephalography/event-related', 'potential', 'experiments', 'in', 'the', 'eegbase', 'resource', '.'], ['querying', 'archetype-based', 'electronic', 'health', 'records', 'using', 'hadoop', 'and', 'dewey', 'encoding', 'of', 'openehr', 'models', '.'], ['introducing', 'a', 'method', 'for', 'transformation', 'of', 'paper-based', 'research', 'data', 'into', 'concept-based', 'representation', 'with', 'openehr', '.'], ['integration', 'of', 'hospital', 'information', 'and', 'clinical', 'decision', 'support', 'systems', 'to', 'enable', 'the', 'reuse', 'of', 'electronic', 'health', 'record', 'data', '.'], ['structuring', 'legacy', 'pathology', 'reports', 'by', 'openehr', 'archetypes', 'to', 'enable', 'semantic', 'querying', '.'], ['a', 'survey', 'of', 'standard', 'information', 'models', 'for', 'clinical', 'decision', 'support', 'systems', '.'], ['applying', 'openehr', \"'s\", 'guideline', 'definition', 'language', 'to', 'the', 'sits', 'international', 'stroke', 'treatment', 'registry', ':', 'a', 'european', 'retrospective', 'observational', 'study', '.'], ['a', 'scalable', 'data', 'access', 'layer', 'to', 'manage', 'structured', 'heterogeneous', 'biomedical', 'data', '.'], ['open', 'data', 'models', 'for', 'smart', 'health', 'interconnected', 'applications', ':', 'the', 'example', 'of', 'openehr', '.'], ['integrating', 'semantic', 'dimension', 'into', 'openehr', 'archetypes', 'for', 'the', 'management', 'of', 'cerebral', 'palsy', 'electronic', 'medical', 'records', '.'], ['automated', 'population', 'of', 'an', 'i2b2', 'clinical', 'data', 'warehouse', 'from', 'an', 'openehr-based', 'data', 'repository', '.'], ['building', 'chronic', 'kidney', 'disease', 'clinical', 'practice', 'guidelines', 'using', 'the', 'openehr', 'guideline', 'definition', 'language', '.'], ['modelling', 'of', 'operative', 'report', 'documents', 'for', 'data', 'integration', 'into', 'an', 'openehr-based', 'enterprise', 'data', 'warehouse', '.'], ['a', 'methodology', 'based', 'on', 'openehr', 'archetypes', 'and', 'software', 'agents', 'for', 'developing', 'e-health', 'applications', 'reusing', 'legacy', 'systems', '.'], ['an', 'implementation', 'of', 'clinical', 'data', 'repository', 'with', 'openehr', 'approach', ':', 'from', 'data', 'modeling', 'to', 'architecture', '.'], ['an', 'update', 'on', 'openehr', 'archetypes', 'in', 'norway', ':', 'response', 'to', 'article', 'christensen', 'b', '&', 'ellingsen', 'g', ':', '``', 'evaluating', 'model-driven', 'development', 'for', 'large-scale', 'ehrs', 'through', 'the', 'openehr', 'approach', \"''\", 'ijmi', 'may', '2016', ',', 'volume', '89', ',', 'pages', '43-54', '.'], ['analysis', 'of', 'the', 'process', 'of', 'representing', 'clinical', 'statements', 'for', 'decision-support', 'applications', ':', 'a', 'comparison', 'of', 'openehr', 'archetypes', 'and', 'hl7', 'virtual', 'medical', 'record', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Utilizando a biblioteca nltk para obter as palavras dos títulos separadas em tokens\n",
    "v_tokens = [[w.lower() for w in nltk.word_tokenize(text)] for text in v_titles]\n",
    "print(v_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 special\n",
      "1 topic\n",
      "2 interoperability\n",
      "3 and\n",
      "4 ehr\n",
      "5 :\n",
      "6 combining\n",
      "7 openehr\n",
      "8 ,\n",
      "9 snomed\n",
      "10 ihe\n",
      "11 continua\n",
      "12 as\n",
      "13 approaches\n",
      "14 to\n",
      "15 on\n",
      "16 national\n",
      "17 ehealth\n",
      "18 .\n",
      "19 bridging\n",
      "20 the\n",
      "21 gap\n",
      "22 between\n",
      "23 social\n",
      "24 technical\n",
      "25 enrolment\n",
      "26 of\n",
      "27 socio-technical\n",
      "28 information\n",
      "29 architects\n",
      "30 cope\n",
      "31 with\n",
      "32 two-level\n",
      "33 model\n",
      "34 epr\n",
      "35 systems\n",
      "36 domain\n",
      "37 modeling\n",
      "38 application\n",
      "39 development\n",
      "40 an\n",
      "41 archetype-\n",
      "42 xml-based\n",
      "43 ehrs\n",
      "44 practical\n",
      "45 experiences\n",
      "46 lessons\n",
      "47 learnt\n",
      "48 applying\n",
      "49 archetype-based\n",
      "50 approach\n",
      "51 electroencephalography/event-related\n",
      "52 potential\n",
      "53 experiments\n",
      "54 in\n",
      "55 eegbase\n",
      "56 resource\n",
      "57 querying\n",
      "58 electronic\n",
      "59 health\n",
      "60 records\n",
      "61 using\n",
      "62 hadoop\n",
      "63 dewey\n",
      "64 encoding\n",
      "65 models\n",
      "66 introducing\n",
      "67 a\n",
      "68 method\n",
      "69 for\n",
      "70 transformation\n",
      "71 paper-based\n",
      "72 research\n",
      "73 data\n",
      "74 into\n",
      "75 concept-based\n",
      "76 representation\n",
      "77 integration\n",
      "78 hospital\n",
      "79 clinical\n",
      "80 decision\n",
      "81 support\n",
      "82 enable\n",
      "83 reuse\n",
      "84 record\n",
      "85 structuring\n",
      "86 legacy\n",
      "87 pathology\n",
      "88 reports\n",
      "89 by\n",
      "90 archetypes\n",
      "91 semantic\n",
      "92 survey\n",
      "93 standard\n",
      "94 's\n",
      "95 guideline\n",
      "96 definition\n",
      "97 language\n",
      "98 sits\n",
      "99 international\n",
      "100 stroke\n",
      "101 treatment\n",
      "102 registry\n",
      "103 european\n",
      "104 retrospective\n",
      "105 observational\n",
      "106 study\n",
      "107 scalable\n",
      "108 access\n",
      "109 layer\n",
      "110 manage\n",
      "111 structured\n",
      "112 heterogeneous\n",
      "113 biomedical\n",
      "114 open\n",
      "115 smart\n",
      "116 interconnected\n",
      "117 applications\n",
      "118 example\n",
      "119 integrating\n",
      "120 dimension\n",
      "121 management\n",
      "122 cerebral\n",
      "123 palsy\n",
      "124 medical\n",
      "125 automated\n",
      "126 population\n",
      "127 i2b2\n",
      "128 warehouse\n",
      "129 from\n",
      "130 openehr-based\n",
      "131 repository\n",
      "132 building\n",
      "133 chronic\n",
      "134 kidney\n",
      "135 disease\n",
      "136 practice\n",
      "137 guidelines\n",
      "138 modelling\n",
      "139 operative\n",
      "140 report\n",
      "141 documents\n",
      "142 enterprise\n",
      "143 methodology\n",
      "144 based\n",
      "145 software\n",
      "146 agents\n",
      "147 developing\n",
      "148 e-health\n",
      "149 reusing\n",
      "150 implementation\n",
      "151 architecture\n",
      "152 update\n",
      "153 norway\n",
      "154 response\n",
      "155 article\n",
      "156 christensen\n",
      "157 b\n",
      "158 &\n",
      "159 ellingsen\n",
      "160 g\n",
      "161 ``\n",
      "162 evaluating\n",
      "163 model-driven\n",
      "164 large-scale\n",
      "165 through\n",
      "166 ''\n",
      "167 ijmi\n",
      "168 may\n",
      "169 2016\n",
      "170 volume\n",
      "171 89\n",
      "172 pages\n",
      "173 43-54\n",
      "174 analysis\n",
      "175 process\n",
      "176 representing\n",
      "177 statements\n",
      "178 decision-support\n",
      "179 comparison\n",
      "180 hl7\n",
      "181 virtual\n",
      "Number of words in dictionary: 182\n"
     ]
    }
   ],
   "source": [
    "# Criação de um dicionário da lista dos documentos encontrados, baseado em seus títulos\n",
    "dictionary = gensim.corpora.Dictionary(v_tokens)\n",
    "\n",
    "for i in range(len(dictionary)):\n",
    "    print(i, dictionary[i])\n",
    "\n",
    "print(\"Number of words in dictionary:\",len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "for d in corpus:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('special', 1)\n",
      "('topic', 1)\n",
      "('interoperability', 2)\n",
      "('and', 2)\n",
      "('ehr', 1)\n",
      "(':', 1)\n",
      "('combining', 1)\n",
      "('openehr', 1)\n",
      "(',', 3)\n",
      "('snomed', 1)\n",
      "('ihe', 1)\n",
      "('continua', 1)\n",
      "('as', 1)\n",
      "('approaches', 1)\n",
      "('to', 1)\n",
      "('on', 1)\n",
      "('national', 1)\n",
      "('ehealth', 1)\n",
      "('.', 1)\n",
      "('bridging', 1)\n",
      "('the', 5)\n",
      "('gap', 1)\n",
      "('between', 1)\n",
      "('social', 1)\n",
      "('and', 1)\n",
      "('technical', 1)\n",
      "(':', 1)\n",
      "('enrolment', 1)\n",
      "('of', 2)\n",
      "('socio-technical', 1)\n",
      "('information', 1)\n",
      "('architects', 1)\n",
      "('to', 1)\n",
      "('cope', 1)\n",
      "('with', 1)\n",
      "('two-level', 1)\n",
      "('model', 1)\n",
      "('epr', 1)\n",
      "('systems', 1)\n",
      "('.', 1)\n",
      "('domain', 1)\n",
      "('modeling', 1)\n",
      "('and', 3)\n",
      "('application', 1)\n",
      "('development', 1)\n",
      "('of', 1)\n",
      "('an', 1)\n",
      "('archetype-', 1)\n",
      "('xml-based', 1)\n",
      "('ehrs', 1)\n",
      "('.', 2)\n",
      "('practical', 1)\n",
      "('experiences', 1)\n",
      "('lessons', 1)\n",
      "('learnt', 1)\n",
      "('applying', 1)\n",
      "('an', 1)\n",
      "('archetype-based', 1)\n",
      "('approach', 1)\n",
      "('to', 1)\n",
      "('electroencephalography/event-related', 1)\n",
      "('potential', 1)\n",
      "('experiments', 1)\n",
      "('in', 1)\n",
      "('the', 1)\n",
      "('eegbase', 1)\n",
      "('resource', 1)\n",
      "('.', 1)\n",
      "('querying', 1)\n",
      "('archetype-based', 1)\n",
      "('electronic', 1)\n",
      "('health', 1)\n",
      "('records', 1)\n",
      "('using', 1)\n",
      "('hadoop', 1)\n",
      "('and', 1)\n",
      "('dewey', 1)\n",
      "('encoding', 1)\n",
      "('of', 1)\n",
      "('openehr', 1)\n",
      "('models', 1)\n",
      "('.', 1)\n",
      "('introducing', 1)\n",
      "('a', 1)\n",
      "('method', 1)\n",
      "('for', 1)\n",
      "('transformation', 1)\n",
      "('of', 1)\n",
      "('paper-based', 1)\n",
      "('research', 1)\n",
      "('data', 1)\n",
      "('into', 1)\n",
      "('concept-based', 1)\n",
      "('representation', 1)\n",
      "('with', 1)\n",
      "('openehr', 1)\n",
      "('.', 1)\n",
      "('integration', 1)\n",
      "('of', 2)\n",
      "('hospital', 1)\n",
      "('information', 1)\n",
      "('and', 1)\n",
      "('clinical', 1)\n",
      "('decision', 1)\n",
      "('support', 1)\n",
      "('systems', 1)\n",
      "('to', 1)\n",
      "('enable', 1)\n",
      "('the', 1)\n",
      "('reuse', 1)\n",
      "('electronic', 1)\n",
      "('health', 1)\n",
      "('record', 1)\n",
      "('data', 1)\n",
      "('.', 1)\n",
      "('structuring', 1)\n",
      "('legacy', 1)\n",
      "('pathology', 1)\n",
      "('reports', 1)\n",
      "('by', 1)\n",
      "('openehr', 1)\n",
      "('archetypes', 1)\n",
      "('to', 1)\n",
      "('enable', 1)\n",
      "('semantic', 1)\n",
      "('querying', 1)\n",
      "('.', 1)\n",
      "('a', 1)\n",
      "('survey', 1)\n",
      "('of', 1)\n",
      "('standard', 1)\n",
      "('information', 1)\n",
      "('models', 1)\n",
      "('for', 1)\n",
      "('clinical', 1)\n",
      "('decision', 1)\n",
      "('support', 1)\n",
      "('systems', 1)\n",
      "('.', 1)\n",
      "('applying', 1)\n",
      "('openehr', 1)\n",
      "(\"'s\", 1)\n",
      "('guideline', 1)\n",
      "('definition', 1)\n",
      "('language', 1)\n",
      "('to', 1)\n",
      "('the', 1)\n",
      "('sits', 1)\n",
      "('international', 1)\n",
      "('stroke', 1)\n",
      "('treatment', 1)\n",
      "('registry', 1)\n",
      "(':', 1)\n",
      "('a', 1)\n",
      "('european', 1)\n",
      "('retrospective', 1)\n",
      "('observational', 1)\n",
      "('study', 1)\n",
      "('.', 1)\n",
      "('a', 1)\n",
      "('scalable', 1)\n",
      "('data', 2)\n",
      "('access', 1)\n",
      "('layer', 1)\n",
      "('to', 1)\n",
      "('manage', 1)\n",
      "('structured', 1)\n",
      "('heterogeneous', 1)\n",
      "('biomedical', 1)\n",
      "('.', 1)\n",
      "('open', 1)\n",
      "('data', 1)\n",
      "('models', 1)\n",
      "('for', 1)\n",
      "('smart', 1)\n",
      "('health', 1)\n",
      "('interconnected', 1)\n",
      "('applications', 1)\n",
      "(':', 1)\n",
      "('the', 1)\n",
      "('example', 1)\n",
      "('of', 1)\n",
      "('openehr', 1)\n",
      "('.', 1)\n",
      "('integrating', 1)\n",
      "('semantic', 1)\n",
      "('dimension', 1)\n",
      "('into', 1)\n",
      "('openehr', 1)\n",
      "('archetypes', 1)\n",
      "('for', 1)\n",
      "('the', 1)\n",
      "('management', 1)\n",
      "('of', 1)\n",
      "('cerebral', 1)\n",
      "('palsy', 1)\n",
      "('electronic', 1)\n",
      "('medical', 1)\n",
      "('records', 1)\n",
      "('.', 1)\n",
      "('automated', 1)\n",
      "('population', 1)\n",
      "('of', 1)\n",
      "('an', 2)\n",
      "('i2b2', 1)\n",
      "('clinical', 1)\n",
      "('data', 2)\n",
      "('warehouse', 1)\n",
      "('from', 1)\n",
      "('openehr-based', 1)\n",
      "('repository', 1)\n",
      "('.', 1)\n",
      "('building', 1)\n",
      "('chronic', 1)\n",
      "('kidney', 1)\n",
      "('disease', 1)\n",
      "('clinical', 1)\n",
      "('practice', 1)\n",
      "('guidelines', 1)\n",
      "('using', 1)\n",
      "('the', 1)\n",
      "('openehr', 1)\n",
      "('guideline', 1)\n",
      "('definition', 1)\n",
      "('language', 1)\n",
      "('.', 1)\n",
      "('modelling', 1)\n",
      "('of', 1)\n",
      "('operative', 1)\n",
      "('report', 1)\n",
      "('documents', 1)\n",
      "('for', 1)\n",
      "('data', 2)\n",
      "('integration', 1)\n",
      "('into', 1)\n",
      "('an', 1)\n",
      "('openehr-based', 1)\n",
      "('enterprise', 1)\n",
      "('warehouse', 1)\n",
      "('.', 1)\n",
      "('a', 1)\n",
      "('methodology', 1)\n",
      "('based', 1)\n",
      "('on', 1)\n",
      "('openehr', 1)\n",
      "('archetypes', 1)\n",
      "('and', 1)\n",
      "('software', 1)\n",
      "('agents', 1)\n",
      "('for', 1)\n",
      "('developing', 1)\n",
      "('e-health', 1)\n",
      "('applications', 1)\n",
      "('reusing', 1)\n",
      "('legacy', 1)\n",
      "('systems', 1)\n",
      "('.', 1)\n",
      "('an', 1)\n",
      "('implementation', 1)\n",
      "('of', 1)\n",
      "('clinical', 1)\n",
      "('data', 2)\n",
      "('repository', 1)\n",
      "('with', 1)\n",
      "('openehr', 1)\n",
      "('approach', 1)\n",
      "(':', 1)\n",
      "('from', 1)\n",
      "('modeling', 1)\n",
      "('to', 1)\n",
      "('architecture', 1)\n",
      "('.', 1)\n",
      "('an', 1)\n",
      "('update', 1)\n",
      "('on', 1)\n",
      "('openehr', 2)\n",
      "('archetypes', 1)\n",
      "('in', 1)\n",
      "('norway', 1)\n",
      "(':', 2)\n",
      "('response', 1)\n",
      "('to', 1)\n",
      "('article', 1)\n",
      "('christensen', 1)\n",
      "('b', 1)\n",
      "('&', 1)\n",
      "('ellingsen', 1)\n",
      "('g', 1)\n",
      "('``', 1)\n",
      "('evaluating', 1)\n",
      "('model-driven', 1)\n",
      "('development', 1)\n",
      "('for', 1)\n",
      "('large-scale', 1)\n",
      "('ehrs', 1)\n",
      "('through', 1)\n",
      "('the', 1)\n",
      "('approach', 1)\n",
      "(\"''\", 1)\n",
      "('ijmi', 1)\n",
      "('may', 1)\n",
      "('2016', 1)\n",
      "(',', 2)\n",
      "('volume', 1)\n",
      "('89', 1)\n",
      "('pages', 1)\n",
      "('43-54', 1)\n",
      "('.', 1)\n",
      "('analysis', 1)\n",
      "('of', 3)\n",
      "('the', 1)\n",
      "('process', 1)\n",
      "('representing', 1)\n",
      "('clinical', 1)\n",
      "('statements', 1)\n",
      "('for', 1)\n",
      "('decision-support', 1)\n",
      "('applications', 1)\n",
      "(':', 1)\n",
      "('a', 1)\n",
      "('comparison', 1)\n",
      "('openehr', 1)\n",
      "('archetypes', 1)\n",
      "('and', 1)\n",
      "('hl7', 1)\n",
      "('virtual', 1)\n",
      "('medical', 1)\n",
      "('record', 1)\n",
      "('.', 1)\n"
     ]
    }
   ],
   "source": [
    "# Descobrindo a frequência dos termos encontrados\n",
    "# 1a tentativa: função FreqDist() da biblioteca NLTK FreqDist(v_titles)    ---> Não funcionou!\n",
    "# 2a tentativa: função Counter da biblioteca collections: as frequências da palavras foram analisadas apenas dentro \n",
    "# de cada título, como pode ser visto abaixo. \n",
    "v_count = 0\n",
    "\n",
    "while v_count <= 19:\n",
    "   contador = Counter(v_tokens[v_count]) \n",
    "   for i in contador.items():\n",
    "     print(i) \n",
    "   v_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Special Topic Interoperability and EHR: Combining openEHR, SNOMED, IHE, and Continua as approaches to interoperability on national eHealth.\",\"Bridging the Gap Between the Social and the Technical: The Enrolment of Socio-Technical Information Architects to Cope with the Two-Level Model of EPR Systems.\",\"Domain Modeling and Application Development of an Archetype- and XML-based EHRS. Practical Experiences and Lessons Learnt.\",\"Applying an Archetype-Based Approach to Electroencephalography/Event-Related Potential Experiments in the EEGBase Resource.\",\"Querying Archetype-Based Electronic Health Records Using Hadoop and Dewey Encoding of openEHR Models.\",\"Introducing a Method for Transformation of Paper-Based Research Data into Concept-Based Representation with openEHR.\",\"Integration of Hospital Information and Clinical Decision Support Systems to Enable the Reuse of Electronic Health Record Data.\",\"Structuring Legacy Pathology Reports by openEHR Archetypes to Enable Semantic Querying.\",\"A Survey of Standard Information Models for Clinical Decision Support Systems.\",\"Applying openEHR's Guideline Definition Language to the SITS international stroke treatment registry: a European retrospective observational study.\",\"A Scalable Data Access Layer to Manage Structured Heterogeneous Biomedical Data.\",\"Open data models for smart health interconnected applications: the example of openEHR.\",\"Integrating semantic dimension into openEHR archetypes for the management of cerebral palsy electronic medical records.\",\"Automated population of an i2b2 clinical data warehouse from an openEHR-based data repository.\",\"Building Chronic Kidney Disease Clinical Practice Guidelines Using the openEHR Guideline Definition Language.\",\"Modelling of Operative Report Documents for Data Integration into an openEHR-Based Enterprise Data Warehouse.\",\"A methodology based on openEHR archetypes and software agents for developing e-health applications reusing legacy systems.\",\"An Implementation of Clinical Data Repository with openEHR Approach: From Data Modeling to Architecture.\",\"An update on OpenEHR archetypes in Norway: Response to article Christensen B & Ellingsen G: \"Evaluating Model-Driven Development for large-scale EHRs through the openEHR approach\" IJMI May 2016, Volume 89, pages 43-54.\",\"Analysis of the process of representing clinical statements for decision-support applications: a comparison of openEHR archetypes and HL7 virtual medical record.\",\n"
     ]
    }
   ],
   "source": [
    "# Descobrindo a frequência dos termos encontrados\n",
    "# Passos: \n",
    "# 1: Transformar os títulos que estão organizados de forma distinta em v_titles, em um único texto longo para que se \n",
    "#    identificar a frequência dos termos entre os títulos dos artigos encontrados já que não estou trabalhando com \n",
    "#    os conteúdos dos documentos.\n",
    "v_count = 0\n",
    "v_texto = ''\n",
    "\n",
    "while v_count <= 19:\n",
    "   v_texto = v_texto + '\"'+ v_titles[v_count] +'\",' \n",
    "   v_count += 1\n",
    "\n",
    "print(v_texto)\n",
    "\n",
    "\n",
    "#   if v_count == 0: \n",
    "#      v_texto = v_texto + '\"'+ v_titles[v_count] +'\",'\n",
    "#   elif v_count >= 1:\n",
    "#      v_texto = v_texto + ' ' + v_titles[v_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"', 42)\n",
      "('S', 18)\n",
      "('p', 87)\n",
      "('e', 234)\n",
      "('c', 83)\n",
      "('i', 132)\n",
      "('a', 165)\n",
      "('l', 83)\n",
      "(' ', 295)\n",
      "('T', 7)\n",
      "('o', 163)\n",
      "('I', 13)\n",
      "('n', 164)\n",
      "('t', 155)\n",
      "('r', 110)\n",
      "('b', 13)\n",
      "('y', 36)\n",
      "('d', 58)\n",
      "('E', 37)\n",
      "('H', 26)\n",
      "('R', 30)\n",
      "(':', 8)\n",
      "('C', 10)\n",
      "('m', 36)\n",
      "('g', 42)\n",
      "(',', 25)\n",
      "('N', 2)\n",
      "('O', 4)\n",
      "('M', 13)\n",
      "('D', 20)\n",
      "('u', 35)\n",
      "('s', 93)\n",
      "('h', 51)\n",
      "('.', 21)\n",
      "('B', 11)\n",
      "('G', 6)\n",
      "('w', 9)\n",
      "('f', 32)\n",
      "('-', 16)\n",
      "('A', 19)\n",
      "('L', 9)\n",
      "('v', 12)\n",
      "('P', 6)\n",
      "('X', 1)\n",
      "('x', 3)\n",
      "('/', 1)\n",
      "('Q', 2)\n",
      "('U', 2)\n",
      "(\"'\", 1)\n",
      "('k', 1)\n",
      "('2', 3)\n",
      "('K', 1)\n",
      "('W', 1)\n",
      "('F', 1)\n",
      "('&', 1)\n",
      "('J', 1)\n",
      "('0', 1)\n",
      "('1', 1)\n",
      "('6', 1)\n",
      "('V', 1)\n",
      "('8', 1)\n",
      "('9', 1)\n",
      "('4', 2)\n",
      "('3', 1)\n",
      "('5', 1)\n",
      "('7', 1)\n"
     ]
    }
   ],
   "source": [
    "# Descobrindo a frequência dos termos encontrados\n",
    "# Passos: \n",
    "# 2: Executar a contagem da frequência com a função counter()\n",
    "# 3: Exibir as frequências de cada termo\n",
    "\n",
    "v_frequencia = Counter(v_texto) \n",
    "for i in v_frequencia.items():\n",
    "  print(i)\n",
    "  v_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
